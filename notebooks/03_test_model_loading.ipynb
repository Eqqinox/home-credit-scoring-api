{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #1e3a8a; background-color: #dbeafe; padding: 12px; border-left: 5px solid #2563eb; margin: 20px 0; font-weight: bold;\">Test de Rechargement du Modèle et Prédiction</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "**Objectif** : Vérifier que tous les artefacts peuvent être rechargés correctement et que le modèle fonctionne.\n",
    "\n",
    "**Tests à effectuer** :\n",
    "1. Rechargement de tous les artefacts (modèle, encoders, features, métriques)\n",
    "2. Vérification de la cohérence des données\n",
    "3. Test de prédiction sur un échantillon\n",
    "4. Validation du format de sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports terminés\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Imports terminés\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_load",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #1e40af; background-color: #eff6ff; padding: 10px; border-left: 4px solid #3b82f6; margin: 15px 0;\">Rechargement des Artefacts</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load_artifacts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RECHARGEMENT DES ARTEFACTS\n",
      "================================================================================\n",
      "\n",
      "1. Chargement du modèle LightGBM...\n",
      "   Type: LGBMClassifier\n",
      "   Nombre d'estimateurs: 300\n",
      "\n",
      "2. Chargement des Label Encoders...\n",
      "   Nombre d'encodeurs: 5\n",
      "   Variables: ['NAME_CONTRACT_TYPE', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'EMERGENCYSTATE_MODE', 'PREV_FLAG_LAST_APPL_PER_CONTRACT_<LAMBDA_0>']\n",
      "\n",
      "3. Chargement des One-Hot Encoders...\n",
      "   Nombre d'encodeurs: 32\n",
      "\n",
      "4. Chargement des noms de features...\n",
      "   Nombre de features: 911\n",
      "   Premières features: ['NAME_CONTRACT_TYPE', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL']\n",
      "\n",
      "5. Chargement des métriques...\n",
      "   AUC-ROC: 0.7826\n",
      "   Recall: 0.6628\n",
      "\n",
      "6. Chargement du seuil optimal...\n",
      "   Seuil optimal: 0.5225\n",
      "\n",
      "Tous les artefacts ont été chargés avec succès\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RECHARGEMENT DES ARTEFACTS\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "models_dir = Path('../models')\n",
    "\n",
    "# 1. Charger le modèle\n",
    "print(\"1. Chargement du modèle LightGBM...\")\n",
    "with open(models_dir / 'model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "print(f\"   Type: {type(model).__name__}\")\n",
    "print(f\"   Nombre d'estimateurs: {model.n_estimators}\")\n",
    "print()\n",
    "\n",
    "# 2. Charger les encoders\n",
    "print(\"2. Chargement des Label Encoders...\")\n",
    "with open(models_dir / 'label_encoders.pkl', 'rb') as f:\n",
    "    label_encoders = pickle.load(f)\n",
    "print(f\"   Nombre d'encodeurs: {len(label_encoders)}\")\n",
    "print(f\"   Variables: {list(label_encoders.keys())}\")\n",
    "print()\n",
    "\n",
    "print(\"3. Chargement des One-Hot Encoders...\")\n",
    "with open(models_dir / 'onehot_encoder.pkl', 'rb') as f:\n",
    "    onehot_encoders = pickle.load(f)\n",
    "print(f\"   Nombre d'encodeurs: {len(onehot_encoders)}\")\n",
    "print()\n",
    "\n",
    "# 3. Charger les noms de features\n",
    "print(\"4. Chargement des noms de features...\")\n",
    "with open(models_dir / 'feature_names.pkl', 'rb') as f:\n",
    "    feature_names = pickle.load(f)\n",
    "print(f\"   Nombre de features: {len(feature_names)}\")\n",
    "print(f\"   Premières features: {feature_names[:5]}\")\n",
    "print()\n",
    "\n",
    "# 4. Charger les métriques\n",
    "print(\"5. Chargement des métriques...\")\n",
    "with open(models_dir / 'metrics.json', 'r') as f:\n",
    "    metrics = json.load(f)\n",
    "print(f\"   AUC-ROC: {metrics['auc_roc']:.4f}\")\n",
    "print(f\"   Recall: {metrics['recall']:.4f}\")\n",
    "print()\n",
    "\n",
    "# 5. Charger le seuil optimal\n",
    "print(\"6. Chargement du seuil optimal...\")\n",
    "with open(models_dir / 'threshold.json', 'r') as f:\n",
    "    threshold_data = json.load(f)\n",
    "optimal_threshold = threshold_data['optimal_threshold']\n",
    "print(f\"   Seuil optimal: {optimal_threshold:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Tous les artefacts ont été chargés avec succès\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_predict",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #1e40af; background-color: #eff6ff; padding: 10px; border-left: 4px solid #3b82f6; margin: 15px 0;\">Test de Prédiction</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "test_predict",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST DE PRÉDICTION\n",
      "================================================================================\n",
      "\n",
      "Chargement d'un échantillon de données...\n",
      "Échantillon chargé: (5, 644)\n",
      "\n",
      "Application du preprocessing...\n",
      "Données encodées: (5, 911)\n",
      "\n",
      "Les noms de features correspondent\n",
      "\n",
      "Génération des prédictions...\n",
      "Prédictions générées\n",
      "\n",
      "RÉSULTATS DES PRÉDICTIONS:\n",
      "--------------------------------------------------------------------------------\n",
      " Client_ID  Vrai_Label  Probabilité  Prédiction_0.5  Prédiction_Optimal\n",
      "         0           1     0.838908               1                   1\n",
      "         1           0     0.105397               0                   0\n",
      "         2           0     0.316887               0                   0\n",
      "         3           0     0.354649               0                   0\n",
      "         4           0     0.438234               0                   0\n",
      "\n",
      "ANALYSE DU RISQUE:\n",
      "--------------------------------------------------------------------------------\n",
      "Client 0: Probabilité=0.8389 | Risque=ÉLEVÉ | Décision=REFUSÉ\n",
      "Client 1: Probabilité=0.1054 | Risque=FAIBLE | Décision=ACCEPTÉ\n",
      "Client 2: Probabilité=0.3169 | Risque=MOYEN | Décision=ACCEPTÉ\n",
      "Client 3: Probabilité=0.3546 | Risque=MOYEN | Décision=ACCEPTÉ\n",
      "Client 4: Probabilité=0.4382 | Risque=MOYEN | Décision=ACCEPTÉ\n",
      "\n",
      "Test de prédiction terminé avec succès\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TEST DE PRÉDICTION\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Charger les données de test\n",
    "print(\"Chargement d'un échantillon de données...\")\n",
    "data_path = Path('../data/app_train_models.csv')\n",
    "df_sample = pd.read_csv(data_path, nrows=5)\n",
    "\n",
    "# Séparer features et target\n",
    "X_sample = df_sample.drop(['TARGET', 'SK_ID_CURR'n], axis=1)\n",
    "y_sample = df_sample['TARGET']\n",
    "\n",
    "print(f\"Échantillon chargé: {X_sample.shape}\")\n",
    "print()\n",
    "\n",
    "# Appliquer le preprocessing (comme dans le notebook de production)\n",
    "print(\"Application du preprocessing...\")\n",
    "X_encoded = X_sample.copy()\n",
    "\n",
    "# Label Encoding\n",
    "for col, encoder in label_encoders.items():\n",
    "    if col in X_encoded.columns:\n",
    "        # Gérer les catégories inconnues\n",
    "        unknown_mask = ~X_encoded[col].isin(encoder.classes_)\n",
    "        if unknown_mask.sum() > 0:\n",
    "            X_encoded.loc[unknown_mask, col] = encoder.classes_[0]\n",
    "        X_encoded[col] = encoder.transform(X_encoded[col])\n",
    "\n",
    "# One-Hot Encoding\n",
    "for col, encoder in onehot_encoders.items():\n",
    "    if col in X_encoded.columns:\n",
    "        encoded_data = encoder.transform(X_encoded[[col]])\n",
    "        feature_names_temp = [f\"{col}_{cat}\" for cat in encoder.categories_[0]]\n",
    "        encoded_df = pd.DataFrame(encoded_data, columns=feature_names_temp, index=X_encoded.index)\n",
    "        X_encoded = X_encoded.drop(columns=[col])\n",
    "        X_encoded = pd.concat([X_encoded, encoded_df], axis=1)\n",
    "\n",
    "# Nettoyer les noms de colonnes\n",
    "X_encoded.columns = X_encoded.columns.str.replace('[^A-Za-z0-9_]', '_', regex=True)\n",
    "\n",
    "print(f\"Données encodées: {X_encoded.shape}\")\n",
    "print()\n",
    "\n",
    "# Vérifier que les colonnes correspondent\n",
    "if list(X_encoded.columns) == feature_names:\n",
    "    print(\"Les noms de features correspondent\")\n",
    "else:\n",
    "    print(\"ATTENTION: Les noms de features ne correspondent pas\")\n",
    "    missing = set(feature_names) - set(X_encoded.columns)\n",
    "    extra = set(X_encoded.columns) - set(feature_names)\n",
    "    if missing:\n",
    "        print(f\"Features manquantes: {len(missing)}\")\n",
    "    if extra:\n",
    "        print(f\"Features en trop: {len(extra)}\")\n",
    "print()\n",
    "\n",
    "# Faire les prédictions\n",
    "print(\"Génération des prédictions...\")\n",
    "y_proba = model.predict_proba(X_encoded)[:, 1]\n",
    "y_pred_default = (y_proba >= 0.5).astype(int)\n",
    "y_pred_optimal = (y_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "print(\"Prédictions générées\")\n",
    "print()\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"RÉSULTATS DES PRÉDICTIONS:\")\n",
    "print(\"-\" * 80)\n",
    "results_df = pd.DataFrame({\n",
    "    'Client_ID': range(len(y_sample)),\n",
    "    'Vrai_Label': y_sample.values,\n",
    "    'Probabilité': y_proba,\n",
    "    'Prédiction_0.5': y_pred_default,\n",
    "    'Prédiction_Optimal': y_pred_optimal\n",
    "})\n",
    "\n",
    "print(results_df.to_string(index=False))\n",
    "print()\n",
    "\n",
    "# Niveau de risque\n",
    "def get_risk_level(proba):\n",
    "    if proba < 0.3:\n",
    "        return 'FAIBLE'\n",
    "    elif proba < 0.6:\n",
    "        return 'MOYEN'\n",
    "    else:\n",
    "        return 'ÉLEVÉ'\n",
    "\n",
    "print(\"ANALYSE DU RISQUE:\")\n",
    "print(\"-\" * 80)\n",
    "for i in range(len(y_sample)):\n",
    "    risk = get_risk_level(y_proba[i])\n",
    "    decision = 'REFUSÉ' if y_pred_optimal[i] == 1 else 'ACCEPTÉ'\n",
    "    print(f\"Client {i}: Probabilité={y_proba[i]:.4f} | Risque={risk} | Décision={decision}\")\n",
    "print()\n",
    "\n",
    "print(\"Test de prédiction terminé avec succès\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_format",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #1e40af; background-color: #eff6ff; padding: 10px; border-left: 4px solid #3b82f6; margin: 15px 0;\">Format de Sortie pour l'API</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "api_format",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FORMAT DE SORTIE POUR L'API\n",
      "================================================================================\n",
      "\n",
      "Exemple de réponse JSON pour l'API:\n",
      "\n",
      "{\n",
      "  \"client_id\": 100001,\n",
      "  \"probability_default\": 0.8389,\n",
      "  \"prediction\": 1,\n",
      "  \"decision\": \"REFUSE\",\n",
      "  \"risk_level\": \"\\u00e9lev\\u00e9\",\n",
      "  \"threshold_used\": 0.5225,\n",
      "  \"model_version\": \"1.0\",\n",
      "  \"timestamp\": \"2025-12-04T22:03:22.550673\"\n",
      "}\n",
      "\n",
      "Format validé pour l'API\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FORMAT DE SORTIE POUR L'API\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Créer le format de réponse pour l'API\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Exemple de réponse JSON pour l'API:\")\n",
    "print()\n",
    "\n",
    "# Prendre le premier client comme exemple\n",
    "client_id = 100001  # ID fictif\n",
    "proba = float(y_proba[0])\n",
    "prediction = int(y_pred_optimal[0])\n",
    "risk = get_risk_level(proba)\n",
    "\n",
    "api_response = {\n",
    "    \"client_id\": client_id,\n",
    "    \"probability_default\": round(proba, 4),\n",
    "    \"prediction\": prediction,\n",
    "    \"decision\": \"REFUSE\" if prediction == 1 else \"APPROVE\",\n",
    "    \"risk_level\": risk.lower(),\n",
    "    \"threshold_used\": round(optimal_threshold, 4),\n",
    "    \"model_version\": \"1.0\",\n",
    "    \"timestamp\": datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "import json\n",
    "print(json.dumps(api_response, indent=2))\n",
    "print()\n",
    "\n",
    "print(\"Format validé pour l'API\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section_summary",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #1e40af; background-color: #eff6ff; padding: 10px; border-left: 4px solid #3b82f6; margin: 15px 0;\">Résumé des Tests</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RÉSUMÉ DES TESTS\n",
      "================================================================================\n",
      "\n",
      "ARTEFACTS TESTÉS:\n",
      "  1. Modèle LightGBM               : OK\n",
      "  2. Label Encoders (5)           : OK\n",
      "  3. One-Hot Encoders (32)        : OK\n",
      "  4. Feature Names (911)          : OK\n",
      "  5. Métriques de référence        : OK\n",
      "  6. Seuil optimal (0.5225)      : OK\n",
      "\n",
      "PRÉDICTIONS TESTÉES:\n",
      "  Nombre d'échantillons testés     : 5\n",
      "  Prédictions réussies             : 5\n",
      "  Format de sortie validé          : OK\n",
      "\n",
      "================================================================================\n",
      "TOUS LES TESTS SONT PASSÉS AVEC SUCCÈS\n",
      "================================================================================\n",
      "\n",
      "Le modèle est prêt à être intégré dans l'API FastAPI\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RÉSUMÉ DES TESTS\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "print(\"ARTEFACTS TESTÉS:\")\n",
    "print(f\"  1. Modèle LightGBM               : OK\")\n",
    "print(f\"  2. Label Encoders ({len(label_encoders)})           : OK\")\n",
    "print(f\"  3. One-Hot Encoders ({len(onehot_encoders)})        : OK\")\n",
    "print(f\"  4. Feature Names ({len(feature_names)})          : OK\")\n",
    "print(f\"  5. Métriques de référence        : OK\")\n",
    "print(f\"  6. Seuil optimal ({optimal_threshold:.4f})      : OK\")\n",
    "print()\n",
    "\n",
    "print(\"PRÉDICTIONS TESTÉES:\")\n",
    "print(f\"  Nombre d'échantillons testés     : {len(y_sample)}\")\n",
    "print(f\"  Prédictions réussies             : {len(y_sample)}\")\n",
    "print(f\"  Format de sortie validé          : OK\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TOUS LES TESTS SONT PASSÉS AVEC SUCCÈS\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "print(\"Le modèle est prêt à être intégré dans l'API FastAPI\")\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (projet6)",
   "language": "python",
   "name": "projet6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
