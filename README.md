# Home Credit - API de Scoring CrÃ©dit (MLOps)

> DÃ©ploiement d'un modÃ¨le de scoring crÃ©dit en production avec approche MLOps complÃ¨te

[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-âœ…-009688.svg)](https://fastapi.tiangolo.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16-336791.svg)](https://www.postgresql.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-âœ…-FF4B4B.svg)](https://streamlit.io/)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED.svg)](https://www.docker.com/)
[![MLflow](https://img.shields.io/badge/MLflow-Tracking-orange.svg)](https://mlflow.org/)
[![LightGBM](https://img.shields.io/badge/Model-LightGBM-green.svg)](https://lightgbm.readthedocs.io/)

---

## ðŸ“‹ Table des matiÃ¨res

1. [Contexte du projet](#contexte-du-projet)
2. [Architecture](#architecture)
3. [Progression](#progression)
4. [Performance](#performance)
5. [Installation](#installation)
6. [Utilisation](#utilisation)
7. [API](#api)
8. [Dashboard Monitoring](#dashboard-monitoring)
9. [Tests](#tests)
10. [Technologies](#technologies)
11. [Auteur](#auteur)

---

## ðŸŽ¯ Contexte du projet

**"PrÃªt Ã  dÃ©penser"** est une sociÃ©tÃ© financiÃ¨re proposant des crÃ©dits Ã  la consommation pour des personnes ayant peu ou pas d'historique de prÃªt.

### Mission

DÃ©velopper un **outil de scoring crÃ©dit** pour :
- Calculer la probabilitÃ© qu'un client rembourse son crÃ©dit
- Classifier automatiquement les demandes (accepter/refuser)
- Monitorer les performances du modÃ¨le en production
- DÃ©tecter les dÃ©rives de donnÃ©es (data drift)

### Contrainte mÃ©tier

Le coÃ»t d'un **Faux NÃ©gatif** (mauvais client acceptÃ©) est **10x** supÃ©rieur au coÃ»t d'un **Faux Positif** (bon client refusÃ©).

â†’ NÃ©cessitÃ© d'optimiser le seuil de dÃ©cision pour minimiser le coÃ»t mÃ©tier total.

---

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client HTTP   â”‚â”€â”€â”€â”€â”€>â”‚   FastAPI API    â”‚â”€â”€â”€â”€â”€>â”‚   PostgreSQL    â”‚
â”‚                 â”‚<â”€â”€â”€â”€â”€â”‚  (Port 8000)     â”‚<â”€â”€â”€â”€â”€â”‚  (PrÃ©dictions)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚                         â”‚
                                  â”‚                         â”‚
                                  v                         v
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚  LightGBM Model  â”‚      â”‚  Streamlit      â”‚
                         â”‚  (Scoring)       â”‚      â”‚  Dashboard      â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚  (Port 8501)    â”‚
                                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Composants

1. **API FastAPI** : 5 endpoints REST (predict, batch, health, model-info, docs)
2. **ModÃ¨le LightGBM** : Scoring crÃ©dit optimisÃ© (AUC = 0.76, seuil = 0.5225)
3. **PostgreSQL** : Stockage prÃ©dictions + features + drift reports
4. **Streamlit** : Dashboard monitoring temps rÃ©el (5 pages)
5. **GitHub Actions** : Pipeline CI/CD automatisÃ©
6. **Docker** : Conteneurisation complÃ¨te

---

## ðŸ“Š Progression

### âœ… Partie 1 - DÃ©veloppement du modÃ¨le (TerminÃ©e)

- âœ… Exploration et nettoyage des donnÃ©es (307k clients, 646 features)
- âœ… Feature engineering et agrÃ©gation des tables
- âœ… EntraÃ®nement et comparaison de modÃ¨les avec MLflow
- âœ… SÃ©lection du meilleur modÃ¨le : **LightGBM** (AUC = 0.76)
- âœ… Optimisation des hyperparamÃ¨tres et du seuil mÃ©tier

### ðŸš€ Partie 2 - Mise en production (100% complÃ©tÃ©e âœ…)

#### Ã‰tape 1 : ContrÃ´le de Version âœ…
- Repository GitHub public
- Structure projet claire
- Historique commits explicites

#### Ã‰tape 2 : API + CI/CD âœ…
- API FastAPI fonctionnelle (5 endpoints)
- Dockerfile + docker-compose.yml
- Tests unitaires (pytest) - **Couverture : 83.46%**
- Pipeline GitHub Actions (test, build, push, deploy)
- DÃ©ploiement Hugging Face Spaces : [API Live](https://eqqinox-credit-scoring-api.hf.space)

#### Ã‰tape 3 : Stockage & Monitoring âœ… (ComplÃ©tÃ©e)
- **Phase 1 âœ…** : Base PostgreSQL (4 tables crÃ©Ã©es)
- **Phase 2 âœ…** : Logging structurÃ© JSON (structlog)
- **Phase 3 âœ…** : IntÃ©gration PostgreSQL (PredictionStorage)
- **Phase 4 âœ…** : Simulation de trafic (114 prÃ©dictions)
- **Phase 5 âœ…** : Dashboard Streamlit (5 pages, 8 visualisations)
- **Phase 6 âœ…** : DÃ©tection Data Drift (Evidently AI) - OpÃ©rationnelle
- **Phase 7 â³** : Documentation (MONITORING.md crÃ©Ã©) - En cours

#### Ã‰tape 4 : Optimisation Performances âœ… (ComplÃ©tÃ©e)
- **Phase 1 âœ…** : Profiling baseline (cProfile + mÃ©triques PostgreSQL)
- **Phase 2 âœ…** : Optimisations preprocessing (A1, A2, A3)
- **Phase 3 âœ…** : Benchmarking (2,000 prÃ©dictions mesurÃ©es)
- **Phase 4 âœ…** : Documentation (OPTIMIZATION_REPORT.md)

**RÃ©sultats** : ðŸš€
- RÃ©duction latence : **-42.78%** (30.67 ms â†’ 17.55 ms)
- AmÃ©lioration throughput : **+74.73%** (32.61 â†’ 56.98 pred/sec)
- Objectif -40% minimum : **ATTEINT**

---

## ðŸš€ Performance

### RÃ©sultats des Optimisations (Ã‰tape 4)

**Objectif** : RÃ©duire la latence de -40% minimum (requis OpenClassrooms)

**MÃ©thodologie** :
1. Profiling avec `cProfile` (2,000 prÃ©dictions)
2. Identification de 3 goulots d'Ã©tranglement (preprocessing 91.2% du temps)
3. ImplÃ©mentation de 3 optimisations ciblÃ©es
4. Benchmarking quantitatif avec graphiques

#### Comparaison Baseline vs Optimized

| MÃ©trique | Baseline (Production) | Optimized | AmÃ©lioration | Statut |
|----------|----------------------|-----------|--------------|--------|
| **Mean** | 30.67 ms | 17.55 ms | **-42.78%** | âœ… |
| **Median (P50)** | 30.49 ms | 17.27 ms | **-43.35%** | âœ… |
| **P95** | 32.45 ms | 17.83 ms | **-45.06%** | âœ… |
| **P99** | 35.11 ms | 18.33 ms | **-47.79%** | âœ… |
| **Throughput** | 32.61 pred/sec | 56.98 pred/sec | **+74.73%** | ðŸš€ |

**Source** :
- Baseline : 1,166 prÃ©dictions production (PostgreSQL 09/12 â†’ 16/12/2025)
- Optimized : 2,000 prÃ©dictions benchmarking (16/12/2025)

#### Optimisations ImplÃ©mentÃ©es

| ID | Optimisation | Description | Gain |
|----|--------------|-------------|------|
| **A1** | Label Encoding VectorisÃ© | PrÃ©-calcul mappings + `df.replace()` pandas au lieu de `LabelEncoder.transform()` sklearn | -30% |
| **A2** | One-Hot Encoding GroupÃ© | UN SEUL `pd.concat()` au lieu de 32 (rÃ©duction O(nÂ²) â†’ O(n)) | -20% |
| **A3** | Caching Colonnes Finales | PrÃ©-calcul ordre colonnes finales (Ã©limination regex sur 911 cols) | -10% |

**Gain cumulÃ© mesurÃ©** : **-42.78%** (lÃ©gÃ¨rement supÃ©rieur Ã  l'estimation -60% grÃ¢ce aux synergies)

#### Impact Business

- **UX amÃ©liorÃ©e** : RÃ©ponse quasi-instantanÃ©e (< 20 ms pour 99% des clients)
- **ScalabilitÃ©** : +75% de capacitÃ© sans upgrade matÃ©riel (4.9M pred/jour vs 2.8M)
- **CoÃ»ts rÃ©duits** : -43% temps CPU par prÃ©diction

#### Documentation

Rapport complet d'optimisation : [`docs/OPTIMIZATION_REPORT.md`](docs/OPTIMIZATION_REPORT.md) (700 lignes)

**Contenu** :
- Analyse baseline (profiling cProfile)
- Optimisations dÃ©taillÃ©es (code AVANT/APRÃˆS)
- RÃ©sultats benchmarks (graphiques + JSON)
- Impact production et dÃ©cisions techniques
- Recommandations futures

**Graphiques gÃ©nÃ©rÃ©s** :
- `reports/benchmarks/performance_comparison.png` (bar chart)
- `reports/benchmarks/performance_boxplot.png` (distributions)

---

## ðŸ“ Structure du projet

```
home-credit-scoring-api/
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ ci-cd.yml                    # Pipeline GitHub Actions
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py                  # FastAPI application
â”‚   â”‚   â”œâ”€â”€ schemas.py               # Pydantic models
â”‚   â”‚   â”œâ”€â”€ predictor.py             # Logique ML
â”‚   â”‚   â”œâ”€â”€ config.py                # Configuration
â”‚   â”‚   â””â”€â”€ preprocessing.py         # Utilitaires
â”‚   â”œâ”€â”€ monitoring/
â”‚   â”‚   â”œâ”€â”€ logger.py                # Logging structurÃ© (structlog)
â”‚   â”‚   â”œâ”€â”€ storage.py               # PostgreSQL ORM (SQLAlchemy)
â”‚   â”‚   â”œâ”€â”€ drift_detector.py        # DÃ©tection drift (Evidently AI)
â”‚   â”‚   â”œâ”€â”€ dashboard.py             # Page d'accueil Streamlit
â”‚   â”‚   â””â”€â”€ pages/
â”‚   â”‚       â”œâ”€â”€ overview.py          # KPIs + filtres temporels
â”‚   â”‚       â”œâ”€â”€ performance.py       # Latences + erreurs
â”‚   â”‚       â”œâ”€â”€ business.py          # Profils clients + montants
â”‚   â”‚       â””â”€â”€ drift.py             # Data drift (rapports HTML)
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ init_database.py         # Init PostgreSQL
â”‚       â”œâ”€â”€ simulate_traffic.py      # Simulation trafic
â”‚       â””â”€â”€ generate_drift_report.py # GÃ©nÃ©ration rapports drift
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_api_endpoints.py
â”‚   â”œâ”€â”€ test_predictor.py
â”‚   â”œâ”€â”€ test_validation.py
â”‚   â””â”€â”€ monitoring/
â”‚       â”œâ”€â”€ test_logger.py
â”‚       â””â”€â”€ test_storage.py
â”œâ”€â”€ models/                          # Artefacts ML
â”‚   â”œâ”€â”€ model.pkl                    # LightGBM
â”‚   â”œâ”€â”€ feature_names.pkl
â”‚   â”œâ”€â”€ label_encoders.pkl
â”‚   â”œâ”€â”€ onehot_encoder.pkl
â”‚   â”œâ”€â”€ metrics.json
â”‚   â””â”€â”€ threshold.json
â”œâ”€â”€ data/
â”‚   â””â”€â”€ reference/
â”‚       â””â”€â”€ train_reference.parquet  # Dataset rÃ©fÃ©rence (272 MiB)
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_Modelisation_MLflow.ipynb
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ drift/                       # Rapports Evidently AI (HTML/JSON)
â”œâ”€â”€ example_single_request.json      # Exemple API (1 client)
â”œâ”€â”€ example_batch_request.json       # Exemple API (3 clients)
â”œâ”€â”€ API_USAGE.md                     # Guide utilisation API
â”œâ”€â”€ MONITORING.md                    # Guide monitoring complet
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ Dockerfile.huggingface
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ðŸš€ Installation

### PrÃ©requis

- **Python 3.11+**
- **PostgreSQL 16** (pour stockage production)
- **UV package manager** (recommandÃ©) ou pip
- **Git**
- **Docker** (optionnel)

### Installation avec UV (recommandÃ©)

```bash
# Cloner le repository
git clone https://github.com/Eqqinox/home-credit-scoring-api.git
cd home-credit-scoring-api

# CrÃ©er et activer l'environnement virtuel
uv venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate     # Windows

# Installer les dÃ©pendances
uv pip install -r requirements.txt
```

### Configuration PostgreSQL

```bash
# Lancer PostgreSQL (macOS avec Homebrew)
brew services start postgresql@16

# Initialiser la base de donnÃ©es
python src/scripts/init_database.py
```

**4 tables crÃ©Ã©es** :
- `predictions` (15 colonnes) : PrÃ©dictions individuelles
- `feature_values` : Top 20 features par prÃ©diction
- `anomalies` : Logs d'erreurs API
- `drift_reports` : Rapports Evidently AI

---

## ðŸŽ® Utilisation

### 1. Lancer l'API FastAPI

```bash
# Mode local (avec logging colorÃ©)
ENVIRONMENT=local LOG_LEVEL=INFO uvicorn src.api.main:app --reload --port 8000

# Mode production (JSON structurÃ©)
ENVIRONMENT=production LOG_LEVEL=INFO uvicorn src.api.main:app --port 8000
```

**AccÃ¨s** :
- API : http://localhost:8000
- Swagger UI : http://localhost:8000/docs
- Redoc : http://localhost:8000/redoc

### 2. Lancer le Dashboard Streamlit

```bash
streamlit run src/monitoring/dashboard.py --server.port 8501
```

**AccÃ¨s** : http://localhost:8501

### 3. GÃ©nÃ©rer du Trafic (Simulation)

```bash
# Simulation de 100 prÃ©dictions avec drift
python src/scripts/simulate_traffic.py --num-predictions 100 --delay 0.5 --drift-prob 0.3
```

**Options** :
- `--num-predictions` : Nombre de prÃ©dictions (dÃ©faut : 10)
- `--delay` : DÃ©lai entre requÃªtes en secondes (dÃ©faut : 0.5)
- `--drift-prob` : ProbabilitÃ© d'appliquer du drift (dÃ©faut : 0.3)
- `--drift-magnitude` : Magnitude du drift Â±% (dÃ©faut : 0.15)

---

## ðŸŒ API

### Endpoints disponibles

| MÃ©thode | Endpoint | Description |
|---------|----------|-------------|
| GET | `/` | Health check de l'API |
| GET | `/model-info` | Informations sur le modÃ¨le |
| POST | `/predict` | PrÃ©diction pour un client |
| POST | `/predict-batch` | PrÃ©dictions en batch (max 100) |
| GET | `/docs` | Documentation Swagger UI |

### Exemple de requÃªte

**PrÃ©diction simple** :

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d @example_single_request.json
```

**RÃ©ponse** :

```json
{
  "client_id": 100001,
  "probability_default": 0.3521,
  "prediction": 0,
  "decision": "approve",
  "risk_level": "MEDIUM",
  "threshold_used": 0.5225,
  "model_version": "1.0.0"
}
```

**Voir `API_USAGE.md` pour plus d'exemples.**

---

## ðŸ“Š Dashboard Monitoring

Le dashboard Streamlit offre **5 pages** de monitoring en temps rÃ©el :

### ðŸ  Page d'Accueil
- Statut API FastAPI (âœ…/âŒ)
- Statut PostgreSQL (âœ…/âŒ)
- MÃ©triques globales
- Guide d'utilisation

### ðŸ“ˆ Page Overview
- **4 KPIs** : Total prÃ©dictions, taux approbation, latence moyenne, taux erreur
- **Filtres temporels** : 24h, 7j, 30j, Tout
- **5 visualisations** :
  - Donut chart : RÃ©partition Approve/Refuse
  - Line chart : Volume de prÃ©dictions par heure
  - Histogram : Distribution des probabilitÃ©s (avec seuil 0.5225)
  - Bar chart : Niveaux de confiance (LOW/MEDIUM/HIGH)

### âš¡ Page Performance
- Boxplot : Distribution des latences par endpoint
- Top 10 : RequÃªtes les plus lentes
- Tableau : Erreurs HTTP (code != 200)

### ðŸ’¼ Page Business
- Pie chart : Profils clients (Approve/Refuse)
- Histogram : Distribution des montants de crÃ©dit

### ðŸ” Page Data Drift (Evidently AI)
- **4 KPIs** : Drift dÃ©tectÃ© (OUI/NON), score de drift, features affectÃ©es, seuil alerte
- **Rapport HTML interactif** : Visualisations Evidently AI (distributions, tests statistiques)
- **Historique** : Line chart Ã©volution des scores de drift dans le temps
- **GÃ©nÃ©ration** : Commande `python src/scripts/generate_drift_report.py --days 7`

**Seuil d'alerte** : 30% des features avec drift â†’ RÃ©entraÃ®nement recommandÃ©

**Auto-refresh** : 30 secondes

---

## ðŸ§ª Tests

### Lancer tous les tests

```bash
pytest tests/ -v --cov=src
```

**Couverture actuelle : 83.46%**

### Tests par module

```bash
# Tests API
pytest tests/test_api_endpoints.py -v

# Tests logger
pytest tests/monitoring/test_logger.py -v

# Tests storage
pytest tests/monitoring/test_storage.py -v
```

### Tests en conditions rÃ©elles

```bash
# VÃ©rifier stockage PostgreSQL
psql -U moon -d credit_scoring_prod -c "SELECT COUNT(*) FROM predictions;"

# Voir les statistiques
python3 -c "
from src.monitoring.storage import PredictionStorage
storage = PredictionStorage(database_url='postgresql://moon:moon@localhost:5432/credit_scoring_prod')
import json
print(json.dumps(storage.get_stats(), indent=2))
storage.close()
"
```

---

## ðŸ³ Docker

### Build et run local

```bash
# Build l'image
docker build -t credit-scoring-api .

# Run le container
docker run -p 8000:8000 credit-scoring-api
```

### Docker Compose (avec PostgreSQL)

```bash
# Lancer tous les services
docker-compose up -d

# Voir les logs
docker-compose logs -f api

# ArrÃªter
docker-compose down
```

---

## ðŸ”§ Technologies

### Data Science & ML
- **Pandas**, **NumPy** : Manipulation de donnÃ©es
- **Scikit-learn** : Preprocessing, mÃ©triques
- **LightGBM** : ModÃ¨le de scoring
- **MLflow** : Tracking expÃ©rimentations

### Backend & API
- **FastAPI** : API REST haute performance
- **Pydantic** : Validation des donnÃ©es
- **Uvicorn** : Serveur ASGI

### Database & Storage
- **PostgreSQL 16** : Base de donnÃ©es production
- **SQLAlchemy** : ORM + Connection pooling
- **Psycopg2** : Driver PostgreSQL

### Monitoring & Logging
- **Streamlit** : Dashboard interactif
- **Plotly** : Visualisations interactives
- **structlog** : Logging structurÃ© JSON
- **Evidently AI** : DÃ©tection data drift (Phase 6)

### Testing & CI/CD
- **Pytest** : Tests unitaires + intÃ©gration
- **pytest-cov** : Couverture de code
- **pytest-asyncio** : Tests async
- **GitHub Actions** : Pipeline CI/CD

### DevOps
- **Docker** : Conteneurisation
- **docker-compose** : Orchestration
- **UV** : Package manager Python moderne
- **Hugging Face Spaces** : DÃ©ploiement cloud

---

## ðŸ“ˆ RÃ©sultats du modÃ¨le

### ModÃ¨le sÃ©lectionnÃ© : LightGBM

| MÃ©trique | Valeur |
|----------|--------|
| **AUC ROC** | 0.76 |
| **Seuil optimal** | 0.5225 |
| **Business Score** | 0.73 |
| **Temps d'entraÃ®nement** | 90s |

**Contrainte mÃ©tier** : CoÃ»t FN = 10x CoÃ»t FP

---

## ðŸ“ Commandes utiles

### PostgreSQL

```bash
# Se connecter
psql -U moon -d credit_scoring_prod

# Voir les tables
\dt

# Compter les prÃ©dictions
SELECT COUNT(*) FROM predictions;

# Stats par dÃ©cision
SELECT decision, COUNT(*) FROM predictions GROUP BY decision;
```

### MLflow

```bash
mlflow ui --port 5000
```

### Tests

```bash
# Tous les tests avec couverture
pytest tests/ -v --cov=src --cov-report=html

# Rapport HTML
open htmlcov/index.html
```

---

## ðŸ“š Documentation

- **API** : `API_USAGE.md` - Guide complet d'utilisation
- **Monitoring** : `MONITORING.md` - Guide systÃ¨me de monitoring et dÃ©tection drift
- **Swagger UI** : http://localhost:8000/docs
- **Redoc** : http://localhost:8000/redoc
- **CLAUDE.md** : Contexte technique complet (non versionnÃ©)

---

## ðŸ”— Liens

- **Repository** : https://github.com/Eqqinox/home-credit-scoring-api
- **API Live** : https://eqqinox-credit-scoring-api.hf.space
- **Swagger Live** : https://eqqinox-credit-scoring-api.hf.space/docs
- **Kaggle** : [Home Credit Default Risk](https://www.kaggle.com/c/home-credit-default-risk)

---

## ðŸ“„ Licence

MIT License

---

## ðŸ‘¨â€ðŸ’» Auteur

**Mounir Meknaci**

- ðŸ“§ Email : meknaci81@gmail.com
- ðŸ’¼ LinkedIn : [Mounir Meknaci](https://www.linkedin.com/in/mounir-meknaci/)
- ðŸŽ“ Formation : Data Scientist / ML Engineer
- ðŸ“‚ Projet : Home Credit Default Risk - Approche MLOps

---

*DerniÃ¨re mise Ã  jour : 15 dÃ©cembre 2025*
