"""
Simulation de trafic API pour le scoring cr√©dit.

G√©n√®re des requ√™tes de pr√©diction en streaming avec variations
pour simuler du data drift et alimenter PostgreSQL.

Usage:
    python src/scripts/simulate_traffic.py [--num-predictions 100] [--delay 0.5]

Requirements:
    - API lanc√©e sur http://localhost:8000
    - PostgreSQL op√©rationnel
    - Dataset: data/reference/train_reference.parquet
"""

import pandas as pd
import requests
import time
import random
import sys
import argparse
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional
from tqdm import tqdm
import json


class TrafficSimulator:
    """
    Simulateur de trafic pour l'API de scoring cr√©dit.

    G√©n√®re des requ√™tes de pr√©diction en streaming avec variations
    pour simuler du data drift.
    """

    def __init__(
        self,
        api_url: str = "http://localhost:8000",
        dataset_path: str = "data/reference/train_reference.parquet",
        num_predictions: int = 100,
        delay_seconds: float = 0.5,
        drift_probability: float = 0.3,
        drift_magnitude: float = 0.15
    ):
        """
        Initialise le simulateur de trafic.

        Args:
            api_url: URL de l'API de scoring
            dataset_path: Chemin vers le dataset de r√©f√©rence (Parquet)
            num_predictions: Nombre de pr√©dictions √† g√©n√©rer
            delay_seconds: D√©lai entre chaque requ√™te (simulation streaming)
            drift_probability: Probabilit√© d'appliquer des variations (0-1)
            drift_magnitude: Magnitude des variations (0-1, ¬±15% par d√©faut)
        """
        self.api_url = api_url
        self.dataset_path = dataset_path
        self.num_predictions = num_predictions
        self.delay_seconds = delay_seconds
        self.drift_probability = drift_probability
        self.drift_magnitude = drift_magnitude

        # Statistiques de la simulation
        self.stats = {
            'total': 0,
            'success': 0,
            'failures': 0,
            'approvals': 0,
            'refusals': 0,
            'response_times': [],
            'drifted_clients': 0
        }

        # Dataset
        self.df: Optional[pd.DataFrame] = None
        self.available_indices: List[int] = []

    @staticmethod
    def prepare_reference_dataset(
        csv_path: str = "data/app_train_models.csv",
        output_path: str = "data/reference/train_reference.parquet"
    ) -> None:
        """
        Convertit le CSV en Parquet (une seule fois).

        Args:
            csv_path: Chemin vers le fichier CSV source
            output_path: Chemin de sortie pour le fichier Parquet
        """
        output_file = Path(output_path)

        # V√©rifier si le fichier parquet existe d√©j√†
        if output_file.exists():
            print(f"‚úÖ Dataset de r√©f√©rence d√©j√† existant : {output_path}")
            return

        print(f"üì¶ Conversion {csv_path} ‚Üí {output_path}...")

        # Cr√©er le r√©pertoire si n√©cessaire
        output_file.parent.mkdir(parents=True, exist_ok=True)

        # Charger et convertir
        df = pd.read_csv(csv_path)

        # Supprimer la colonne TARGET (pas n√©cessaire pour la simulation)
        if 'TARGET' in df.columns:
            df = df.drop(columns=['TARGET'])

        # Sauvegarder en Parquet (compression gzip)
        df.to_parquet(output_path, compression='gzip', index=False)

        print(f"‚úÖ Conversion termin√©e : {len(df)} lignes, {len(df.columns)} colonnes")
        print(f"   Taille CSV    : {Path(csv_path).stat().st_size / 1024**2:.1f} MiB")
        print(f"   Taille Parquet: {output_file.stat().st_size / 1024**2:.1f} MiB")

    def load_dataset(self) -> pd.DataFrame:
        """
        Charge le dataset de r√©f√©rence depuis le fichier Parquet.

        Returns:
            DataFrame pr√™t pour l'API

        Raises:
            FileNotFoundError: Si le dataset n'existe pas
        """
        dataset_file = Path(self.dataset_path)

        if not dataset_file.exists():
            # Essayer de le cr√©er depuis le CSV
            csv_path = Path("data/app_train_models.csv")
            if csv_path.exists():
                print(f"‚ö†Ô∏è  Dataset Parquet manquant, conversion depuis CSV...")
                self.prepare_reference_dataset()
            else:
                raise FileNotFoundError(
                    f"Dataset introuvable : {self.dataset_path}\n"
                    f"CSV source √©galement introuvable : {csv_path}"
                )

        # Charger le Parquet
        self.df = pd.read_parquet(self.dataset_path)

        # Initialiser les indices disponibles
        self.available_indices = list(range(len(self.df)))

        return self.df

    def select_random_clients(self, n: int) -> List[Dict[str, Any]]:
        """
        S√©lectionne n clients al√©atoires du dataset.

        Args:
            n: Nombre de clients √† s√©lectionner

        Returns:
            Liste de dictionnaires (JSON-ready)
        """
        if not self.available_indices:
            # R√©initialiser si on a √©puis√© les clients
            self.available_indices = list(range(len(self.df)))

        # S√©lectionner n indices al√©atoires
        selected_indices = random.sample(
            self.available_indices,
            min(n, len(self.available_indices))
        )

        # Retirer ces indices pour √©viter les doublons
        for idx in selected_indices:
            self.available_indices.remove(idx)

        # Convertir en dictionnaires
        clients = []
        for idx in selected_indices:
            client_data = self.df.iloc[idx].to_dict()

            # Convertir les NaN en None pour JSON
            client_data = {
                k: (None if pd.isna(v) else v)
                for k, v in client_data.items()
            }

            clients.append(client_data)

        return clients

    def apply_drift_variations(self, client_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Applique des variations pour simuler du data drift.

        Args:
            client_data: Donn√©es originales du client

        Returns:
            Donn√©es modifi√©es avec drift
        """
        drifted = client_data.copy()

        # Features num√©riques √† faire varier (revenus, cr√©dits, mensualit√©s)
        numeric_features = [
            'AMT_INCOME_TOTAL',
            'AMT_CREDIT',
            'AMT_ANNUITY',
            'AMT_GOODS_PRICE'
        ]

        for feature in numeric_features:
            if feature in drifted and drifted[feature] is not None:
                # Variation : ¬±drift_magnitude
                variation = random.uniform(
                    1 - self.drift_magnitude,
                    1 + self.drift_magnitude
                )
                drifted[feature] = float(drifted[feature]) * variation

        # EXT_SOURCE : L√©g√®re d√©gradation pour simuler du drift
        ext_sources = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']
        for feature in ext_sources:
            if feature in drifted and drifted[feature] is not None:
                # Variation plus faible : ¬±10%
                variation = random.uniform(0.9, 1.1)
                drifted[feature] = float(drifted[feature]) * variation
                # Garder dans [0, 1]
                drifted[feature] = max(0.0, min(1.0, drifted[feature]))

        # DAYS_EMPLOYED : Augmentation progressive (clients vieillissent)
        if 'DAYS_EMPLOYED' in drifted and drifted['DAYS_EMPLOYED'] is not None:
            # Ajouter entre 0 et 365 jours d'anciennet√© (valeurs n√©gatives)
            drifted['DAYS_EMPLOYED'] = float(drifted['DAYS_EMPLOYED']) - random.randint(0, 365)

        return drifted

    def send_prediction_request(
        self,
        client_data: Dict[str, Any]
    ) -> Tuple[bool, Dict[str, Any], float]:
        """
        Envoie une requ√™te de pr√©diction √† l'API.

        Args:
            client_data: Donn√©es du client

        Returns:
            (success, response_data, elapsed_time_ms)
        """
        url = f"{self.api_url}/predict"
        headers = {"Content-Type": "application/json"}

        try:
            start = time.time()
            response = requests.post(
                url,
                json=client_data,
                headers=headers,
                timeout=10
            )
            elapsed_ms = (time.time() - start) * 1000

            if response.status_code == 200:
                return True, response.json(), elapsed_ms
            else:
                return False, {
                    'error': f"HTTP {response.status_code}",
                    'detail': response.text[:200]
                }, elapsed_ms

        except requests.exceptions.Timeout:
            return False, {'error': 'Timeout (>10s)'}, 10000.0
        except requests.exceptions.ConnectionError:
            return False, {'error': 'Connection refused'}, 0.0
        except Exception as e:
            return False, {'error': str(e)}, 0.0

    def verify_api_health(self) -> bool:
        """
        V√©rifie que l'API est accessible et op√©rationnelle.

        Returns:
            True si l'API r√©pond, sinon l√®ve une exception

        Raises:
            ConnectionError: Si l'API n'est pas accessible
        """
        try:
            response = requests.get(f"{self.api_url}/", timeout=5)
            if response.status_code == 200:
                data = response.json()
                print(f"‚úÖ API op√©rationnelle (version {data.get('model_version', 'inconnue')})")
                return True
            else:
                raise ConnectionError(f"API retourne HTTP {response.status_code}")
        except requests.exceptions.ConnectionError:
            raise ConnectionError(
                f"L'API n'est pas accessible sur {self.api_url}\n"
                f"Lancez l'API avec : uvicorn src.api.main:app --reload"
            )
        except Exception as e:
            raise ConnectionError(f"Erreur lors de la v√©rification de l'API : {e}")

    def _log_result(
        self,
        request_num: int,
        client_data: Dict[str, Any],
        response: Dict[str, Any],
        success: bool,
        elapsed_ms: float
    ) -> None:
        """
        Log le r√©sultat d'une pr√©diction.

        Args:
            request_num: Num√©ro de la requ√™te
            client_data: Donn√©es envoy√©es
            response: R√©ponse de l'API
            success: Succ√®s ou √©chec
            elapsed_ms: Temps de r√©ponse en ms
        """
        if success:
            client_id = response.get('client_id', client_data.get('SK_ID_CURR', 'N/A'))
            decision = response.get('decision', 'unknown')
            proba = response.get('probability_default', 0.0)

            # Mettre √† jour les stats
            self.stats['approvals'] += 1 if decision == 'approve' else 0
            self.stats['refusals'] += 1 if decision == 'refuse' else 0

            # Log succinct (on a d√©j√† la barre de progression)
            # print(f"[{request_num:3d}] Client {client_id} ‚Üí {decision.upper():7s} (proba={proba:.3f}, {elapsed_ms:.1f}ms)")
        else:
            error_msg = response.get('error', 'Unknown error')
            print(f"\n‚ùå [{request_num:3d}] ERREUR : {error_msg}")

    def run_simulation(self) -> None:
        """
        Lance la simulation compl√®te.
        """
        print(f"\nüöÄ D√©marrage de la simulation ({self.num_predictions} pr√©dictions)...")

        # Barre de progression
        with tqdm(total=self.num_predictions, desc="Simulation", unit="req") as pbar:
            for i in range(self.num_predictions):
                # 1. S√©lectionner un client al√©atoire
                client = self.select_random_clients(1)[0]

                # 2. Appliquer drift (probabilit√© drift_probability)
                drift_applied = False
                if random.random() < self.drift_probability:
                    client = self.apply_drift_variations(client)
                    drift_applied = True
                    self.stats['drifted_clients'] += 1

                # 3. Envoyer la requ√™te
                success, response, elapsed_ms = self.send_prediction_request(client)

                # 4. Mettre √† jour les stats
                self.stats['total'] += 1
                if success:
                    self.stats['success'] += 1
                    self.stats['response_times'].append(elapsed_ms)
                else:
                    self.stats['failures'] += 1

                # 5. Logger le r√©sultat
                self._log_result(i + 1, client, response, success, elapsed_ms)

                # 6. Attendre avant la prochaine requ√™te (streaming)
                if i < self.num_predictions - 1:  # Pas de d√©lai apr√®s la derni√®re
                    time.sleep(self.delay_seconds)

                # 7. Mettre √† jour la barre de progression
                pbar.update(1)

    def get_statistics(self) -> Dict[str, Any]:
        """
        Retourne les statistiques de la simulation.

        Returns:
            Dictionnaire de statistiques
        """
        success_rate = (self.stats['success'] / self.stats['total'] * 100) if self.stats['total'] > 0 else 0
        approval_rate = (self.stats['approvals'] / self.stats['success'] * 100) if self.stats['success'] > 0 else 0
        refusal_rate = (self.stats['refusals'] / self.stats['success'] * 100) if self.stats['success'] > 0 else 0

        avg_response_time = (
            sum(self.stats['response_times']) / len(self.stats['response_times'])
            if self.stats['response_times'] else 0
        )

        return {
            'total': self.stats['total'],
            'success': self.stats['success'],
            'failures': self.stats['failures'],
            'success_rate': success_rate,
            'approvals': self.stats['approvals'],
            'refusals': self.stats['refusals'],
            'approval_rate': approval_rate,
            'refusal_rate': refusal_rate,
            'avg_response_time': avg_response_time,
            'drifted_clients': self.stats['drifted_clients']
        }


def main():
    """Point d'entr√©e principal du script."""
    parser = argparse.ArgumentParser(
        description="Simulateur de trafic pour l'API de scoring cr√©dit"
    )
    parser.add_argument(
        "--num-predictions",
        type=int,
        default=100,
        help="Nombre de pr√©dictions √† g√©n√©rer (d√©faut: 100)"
    )
    parser.add_argument(
        "--delay",
        type=float,
        default=0.5,
        help="D√©lai entre requ√™tes en secondes (d√©faut: 0.5)"
    )
    parser.add_argument(
        "--api-url",
        type=str,
        default="http://localhost:8000",
        help="URL de l'API (d√©faut: http://localhost:8000)"
    )
    parser.add_argument(
        "--drift-prob",
        type=float,
        default=0.3,
        help="Probabilit√© de drift (0-1, d√©faut: 0.3)"
    )
    parser.add_argument(
        "--drift-mag",
        type=float,
        default=0.15,
        help="Magnitude du drift (0-1, d√©faut: 0.15)"
    )

    args = parser.parse_args()

    # Banni√®re
    print("=" * 80)
    print("SIMULATION DE TRAFIC - HOME CREDIT SCORING API")
    print("=" * 80)
    print(f"Configuration:")
    print(f"  - Nombre de pr√©dictions : {args.num_predictions}")
    print(f"  - D√©lai entre requ√™tes  : {args.delay}s")
    print(f"  - Probabilit√© de drift  : {args.drift_prob * 100}%")
    print(f"  - Magnitude du drift    : ¬±{args.drift_mag * 100}%")
    print("=" * 80)

    # Initialiser le simulateur
    simulator = TrafficSimulator(
        api_url=args.api_url,
        num_predictions=args.num_predictions,
        delay_seconds=args.delay,
        drift_probability=args.drift_prob,
        drift_magnitude=args.drift_mag
    )

    try:
        # 1. V√©rifier que l'API est accessible
        print("\n[1/3] V√©rification de l'API...")
        simulator.verify_api_health()

        # 2. Charger le dataset
        print("\n[2/3] Chargement du dataset...")
        simulator.load_dataset()
        print(f"‚úÖ {len(simulator.df)} clients disponibles")

        # 3. Lancer la simulation
        print("\n[3/3] Lancement de la simulation...")
        start_time = time.time()
        simulator.run_simulation()
        elapsed = time.time() - start_time

        # 4. Afficher les statistiques
        print("\n" + "=" * 80)
        print("R√âSULTATS DE LA SIMULATION")
        print("=" * 80)
        stats = simulator.get_statistics()
        print(f"Dur√©e totale          : {elapsed:.2f}s")
        print(f"Requ√™tes envoy√©es     : {stats['total']}")
        print(f"Succ√®s                : {stats['success']} ({stats['success_rate']:.1f}%)")
        print(f"√âchecs                : {stats['failures']}")
        print(f"Approbations          : {stats['approvals']} ({stats['approval_rate']:.1f}%)")
        print(f"Refus                 : {stats['refusals']} ({stats['refusal_rate']:.1f}%)")
        print(f"Temps moyen           : {stats['avg_response_time']:.2f}ms")
        print(f"Clients avec drift    : {stats['drifted_clients']}")
        print("=" * 80)

        print("\n‚úÖ Simulation termin√©e avec succ√®s !")
        sys.exit(0)

    except Exception as e:
        print(f"\n‚ùå ERREUR : {e}")
        print("\nV√©rifications :")
        print("  1. L'API est-elle lanc√©e ? ‚Üí uvicorn src.api.main:app --reload")
        print("  2. PostgreSQL est-il actif ? ‚Üí brew services list")
        print("  3. Le dataset existe-t-il ? ‚Üí ls -lh data/")
        sys.exit(1)


if __name__ == "__main__":
    main()
